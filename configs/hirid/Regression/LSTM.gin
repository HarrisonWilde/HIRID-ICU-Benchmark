import gin.torch.external_configurables
import icu_benchmarks.models.wrappers
import icu_benchmarks.models.encoders
import icu_benchmarks.models.utils
import icu_benchmarks.data.loader


EMB = 231
LR = 3e-4
HIDDEN = 64
NUM_CLASSES = 1
DEPTH = 1
BS = 64
EPOCHS = 1000
TASK = 'Dynamic_UrineOutput_2Hours_Reg'
RES = 1
RES_LAB = 1
MAXLEN = 2016
LOSS_WEIGHT = None

# Train params
train_common.model = @DLWrapper()
train_common.dataset_fn = @ICUVariableLengthDataset
train_common.data_path = '/data/harry/hirid/ml_stage/ml_stage_12h.h5'
train_common.do_test = True


DLWrapper.encoder = @LSTM()
DLWrapper.loss = @mse_loss
DLWrapper.optimizer_fn = @Adam
DLWrapper.train.epochs = %EPOCHS
DLWrapper.train.batch_size = %BS
DLWrapper.train.patience = 10
DLWrapper.train.min_delta = 1e-4


ICUVariableLengthLoaderTables.splits = ['train','test','val']
ICUVariableLengthLoaderTables.task = %TASK
ICUVariableLengthLoaderTables.data_resampling = %RES
ICUVariableLengthLoaderTables.label_resampling = %RES_LAB
ICUVariableLengthDataset.maxlen = %MAXLEN
ICUVariableLengthDataset.scale_label = True

# Optimizer params
Adam.lr = %LR
Adam.weight_decay = 1e-6

# Encoder params
LSTM.input_dim = %EMB
LSTM.hidden_dim = %HIDDEN
LSTM.layer_dim = %DEPTH
LSTM.num_classes = %NUM_CLASSES


